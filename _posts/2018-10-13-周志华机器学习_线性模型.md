<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>
## 基本形式
### 一般向量形式:
$f(\boldsymbol{x}) = \boldsymbol{\omega}^T*\boldsymbol{x}+b$
#### 优点:
1. 非线性模型可由线性模型通过引入层级结构和高维映射得到
2. 具有很好的解释性(哪一个参数更为重要)

## 线性回归
根据给定数据集，是给定一个线性模型尽可能准确的预测实值的输出标记
最小化均方误差的模型求解方法即为最小二乘法
$$(\boldsymbol{\omega}^*, b^*) = \underset{(\boldsymbol{\omega},b)}{\text{argmin}}\sum_{i=1}^{m}(y_i-\boldsymbol{\omega}*\boldsymbol{x_i}-b)$$
上式中样本 $\boldsymbol{x_i}$ 由多个属性描述,称为多元线性回归

### 广义线性模型
\begin{align}
y = g^{-1}(\boldsymbol{\omega}^T\boldsymbol{x}+b)
\end{align}
$g()$ 为单调可微函数，当对应输出不为线性变化时引入 $g()$。比如输出在指数尺度上变化时，引入对数，则输出就可近似为线性

### 对数几率回归
寻找一个单调可谓的函数将分类任务的真实标记 $y$ 与线性回归函数的预测值联系起来，拿2分类任务为例，简单的方法是选择单位阶阶跃函数，但是该函数并不连续，因此选择类似的对数几率函数
\begin{align}
f(x) = \frac{1}{1+e^{-(\omega x + b)}}
\end{align}
对数几率函数是任意阶可导的凸函数

#### 由对数几率函数确定 $ \boldsymbol{\omega}$ 和 $b$
对数几率函数可变化为
\begin{align}
ln\frac{y}{1-y} = \boldsymbol{\omega}^T\boldsymbol{x} + b
\end{align}
令 $y = p(y=1\;|\;\boldsymbol{x})$，则 $1-y = p(y=0\;|\;\boldsymbol{x})$
所以
\begin{align}
p(y=1\;|\;\boldsymbol{x}) = \frac{e^{\boldsymbol{\omega}^T\boldsymbol{x} + b}}{1+e^{\boldsymbol{\omega}^T\boldsymbol{x}+b}}
\end{align}
\begin{align}
p(y=0\;|\;\boldsymbol{x}) = \frac{1}{1+e^{\boldsymbol{\omega}^T\boldsymbol{x}+b}}
\end{align}
然后通过最大似然法估计参数，根据给定模型，对数回归模型最大化‘对数似然’
\begin{align}
l(\boldsymbol{\omega}, b) = \sum_{i=1}^{m}\ln p(y_i\;|\;\boldsymbol{x};\boldsymbol{\omega},b)
\end{align}
即使得m个样本的预测为真是标记的概率最大
为了表示方便，可以将概率 $p$ 表示为
\begin{align}
p(y_i\;|\;\boldsymbol{x}_i;\boldsymbol{\omega},b) = y_ip_1(\boldsymbol{x,\omega},b) + (1-y_i)p_0(\boldsymbol{x,\omega},b)
\end{align}
$p_1$表示预测为1的概率，$p_2$表示为预测为0的概率，则 $p_1 = 1 - p_0$
所以原式可表示为
\begin{align}
p(y_i\;|\;\boldsymbol{x}_i;\boldsymbol{\omega},b) = y_i\;p(\boldsymbol{x,\omega},b) + (1-y_i)\;(1-p(\boldsymbol{x,\omega},b)
\end{align}
## 线性判别分析 (LDA)
### 思想
给定训练样集，设法将样例投影到一条直线上，使得同类样例尽量接近，异样样例尽量远离
### 求解
设投影直线的方向为 $\boldsymbol{\omega}$, $\boldsymbol{X_i}, \boldsymbol{\mu_i}, \boldsymbol{\Sigma_i}$ 表示第 $i$ 个样本集合，均值向量和协方差矩阵。均值向量的投影为 $\boldsymbol{\omega}^T\boldsymbol{\mu_i}$，协方差矩阵的投影为 $\boldsymbol{\mu_i^T\Sigma_i\mu_i}$
使同类的投影尽可能近即使协方差矩阵的投影尽可能的小，使不同类的投影尽可能的远即使均值的投影距离尽可能大
$$J = \frac{||\boldsymbol{\omega^T\mu_0-\omega^T\mu_1}||_2^2}{\boldsymbol{\omega^T\Sigma_0\omega + \omega^T\Sigma_1\omega}} = \frac{\boldsymbol{\omega^T(\mu_0-\mu_1)(\mu_0-\mu_1)^T\omega}}{\boldsymbol{\omega^T(\Sigma_0+\Sigma_1)\omega}}$$
令 $$\boldsymbol{S_\omega = \Sigma_0 + \Sigma_1}  $$为类内散度矩阵，$$\boldsymbol{S_b = (\mu_0-\mu_1)(\mu_0-\mu_1)^T}  $$为类间散度矩阵，$S_\omega, S_b$ 为广义瑞丽商(generalized Rayleigh quotient)
### 多分类任务
设有 $N$ 个类，第 $i$ 个类的示例数为 $m_i$，定义全局散度矩阵
\begin{align}
\boldsymbol{S_t} = \sum_{i=1}^{m}(\boldsymbol{(x_i-\mu)(x_i - \mu)^T}
\end{align}
$\boldsymbol{\mu}$ 为所有示例的均值
类内散度矩阵 $\boldsymbol{S_\omega}$ 为每个类别的散度矩阵之和，即 $$\boldsymbol{S_\omega} = \sum_{i=1}^{m} \boldsymbol{S_{\omega_i}}$$，其中 $$S_{\omega_i} = \sum_{j=1}^{m_i}(\boldsymbol{(x_j-\mu_i)(x_j-\mu_i)^T}$$
$$\boldsymbol{S_b = S_t - S_\omega} = \sum_{i=1}^{N}m_i\boldsymbol{(\mu_i -\mu)(\mu_i - \mu)^T}$$
多分类的LDA有多种实现方法，选择 $\boldsymbol{S_\omega, S_t, S_b}$ 任意两个都可。
$\boldsymbol{W}$  是一个投影矩阵，将多分类问题投影到 $d'$ 维空间，$d'\ll d$，可用于降维。
## 多分类问题
多分类问题的基本思路是拆解法，将多分类任务柴蔚若干个二分类任务

**一对一(OvO)**: 将N个类别两两配对，形成 $N(N-1)/2$ 个分类任务，最终预测结果根据分类结果中数目最多的类别判断

**一对多(OvR)**: 将一个类别视为正，其余所有均视为负。若只有一个类别为真，那么该类为预测结果；若多个类别都判断为真，根据每个判断结果的置信度预测最终结果。

**多对多(MvM)**:
对 $N$ 个数据集进行 $M$ 次分类，每次将一部分作为正数据集，一部分作为负数据集，于是可以训练 $M$ 个分类器。最常用的为“纠错输出ma





